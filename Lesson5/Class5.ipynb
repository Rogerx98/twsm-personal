{"cells":[{"cell_type":"markdown","metadata":{"id":"view-in-github"},"source":["<a href=\"https://colab.research.google.com/github/markusloecher/DataScience2021/blob/main/TWSM/Class5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"]},{"cell_type":"markdown","source":["### Libraries"],"metadata":{"id":"L0HoGesYBC1E"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')\n","DATA_PATH = \"/content/drive/Othercomputers/Mi portátil/Master/GitHub/twsm-PERSONAL\"\n","\n","#from TWSM import *\n","from tensorflow import keras\n","from tensorflow.keras import layers\n","import spacy\n","## Import packages\n","import pickle\n","import pandas as pd\n","from gensim.models import Word2Vec\n","\n","# run this from a normal command line\n","#!python -m spacy download en_core_web_md #160MB\n","\n","#can I download this to a local file instead and load it fom drive?\n"],"metadata":{"id":"4k1Km8WrvyWM","colab":{"base_uri":"https://localhost:8080/"},"outputId":"0df4f8ac-bc79-496b-f53a-bb84ff4b45b4","executionInfo":{"status":"ok","timestamp":1651584252453,"user_tz":-120,"elapsed":22938,"user":{"displayName":"Roger Pujol","userId":"07983155497047424279"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["import numpy as np"],"metadata":{"id":"V10qiyfBVq_e","executionInfo":{"status":"ok","timestamp":1651672268715,"user_tz":-120,"elapsed":536,"user":{"displayName":"Roger Pujol","userId":"07983155497047424279"}}},"execution_count":50,"outputs":[]},{"cell_type":"code","source":["!pip install whatlies"],"metadata":{"id":"RaL0PTnTkiWJ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1651583761696,"user_tz":-120,"elapsed":16204,"user":{"displayName":"Roger Pujol","userId":"07983155497047424279"}},"outputId":"149cb424-8c3f-41f7-b200-63e672bc91f8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting whatlies\n","  Downloading whatlies-0.6.5-py2.py3-none-any.whl (85 kB)\n","\u001b[?25l\r\u001b[K     |███▉                            | 10 kB 16.6 MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 20 kB 22.9 MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 30 kB 15.3 MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 40 kB 11.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 51 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 61 kB 6.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 71 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 81 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 85 kB 1.6 MB/s \n","\u001b[?25hRequirement already satisfied: matplotlib>=3.2.0 in /usr/local/lib/python3.7/dist-packages (from whatlies) (3.2.2)\n","Requirement already satisfied: altair>=4.0.1 in /usr/local/lib/python3.7/dist-packages (from whatlies) (4.2.0)\n","Requirement already satisfied: scikit-learn>=0.24.0 in /usr/local/lib/python3.7/dist-packages (from whatlies) (1.0.2)\n","Collecting gensim~=3.8.3\n","  Downloading gensim-3.8.3-cp37-cp37m-manylinux1_x86_64.whl (24.2 MB)\n","\u001b[K     |████████████████████████████████| 24.2 MB 2.3 MB/s \n","\u001b[?25hCollecting bpemb>=0.3.0\n","  Downloading bpemb-0.3.3-py3-none-any.whl (19 kB)\n","Requirement already satisfied: entrypoints in /usr/local/lib/python3.7/dist-packages (from altair>=4.0.1->whatlies) (0.4)\n","Requirement already satisfied: toolz in /usr/local/lib/python3.7/dist-packages (from altair>=4.0.1->whatlies) (0.11.2)\n","Requirement already satisfied: pandas>=0.18 in /usr/local/lib/python3.7/dist-packages (from altair>=4.0.1->whatlies) (1.3.5)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from altair>=4.0.1->whatlies) (2.11.3)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from altair>=4.0.1->whatlies) (1.21.6)\n","Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.7/dist-packages (from altair>=4.0.1->whatlies) (4.3.3)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from bpemb>=0.3.0->whatlies) (4.64.0)\n","Collecting sentencepiece\n","  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n","\u001b[K     |████████████████████████████████| 1.2 MB 40.6 MB/s \n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from bpemb>=0.3.0->whatlies) (2.23.0)\n","Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.7/dist-packages (from gensim~=3.8.3->whatlies) (1.4.1)\n","Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from gensim~=3.8.3->whatlies) (1.15.0)\n","Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.7/dist-packages (from gensim~=3.8.3->whatlies) (6.0.0)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from jsonschema>=3.0->altair>=4.0.1->whatlies) (4.11.3)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from jsonschema>=3.0->altair>=4.0.1->whatlies) (4.2.0)\n","Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema>=3.0->altair>=4.0.1->whatlies) (0.18.1)\n","Requirement already satisfied: importlib-resources>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema>=3.0->altair>=4.0.1->whatlies) (5.7.1)\n","Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema>=3.0->altair>=4.0.1->whatlies) (21.4.0)\n","Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.7/dist-packages (from importlib-resources>=1.4.0->jsonschema>=3.0->altair>=4.0.1->whatlies) (3.8.0)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.2.0->whatlies) (0.11.0)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.2.0->whatlies) (3.0.8)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.2.0->whatlies) (2.8.2)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.2.0->whatlies) (1.4.2)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.18->altair>=4.0.1->whatlies) (2022.1)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.24.0->whatlies) (3.1.0)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.24.0->whatlies) (1.1.0)\n","Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->altair>=4.0.1->whatlies) (2.0.1)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->bpemb>=0.3.0->whatlies) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->bpemb>=0.3.0->whatlies) (2021.10.8)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->bpemb>=0.3.0->whatlies) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->bpemb>=0.3.0->whatlies) (1.24.3)\n","Installing collected packages: sentencepiece, gensim, bpemb, whatlies\n","  Attempting uninstall: gensim\n","    Found existing installation: gensim 3.6.0\n","    Uninstalling gensim-3.6.0:\n","      Successfully uninstalled gensim-3.6.0\n","Successfully installed bpemb-0.3.3 gensim-3.8.3 sentencepiece-0.1.96 whatlies-0.6.5\n"]}]},{"cell_type":"markdown","source":["https://stackoverflow.com/questions/56927602/unable-to-load-the-spacy-model-en-core-web-lg-on-google-colab\n","\n","Now, *** restart the colab runtime *** !!"],"metadata":{"id":"n359prBLepXE"}},{"cell_type":"markdown","source":["## word2vec in spacy"],"metadata":{"id":"sO_IQ0wFdJVJ"}},{"cell_type":"code","source":["import spacy\n","# Load the spacy model that you have installed\n","nlp = spacy.load('en_core_web_md')\n","\n","# process a sentence using the model\n","doc = nlp(\"The sun is shining brightly today but the moon is not\")\n","\n","# It's that simple - all of the vectors and words are assigned after this point\n","# Get the vector for 'text':\n","doc[3].vector\n","\n","# Get the mean vector for the entire sentence (useful for sentence classification etc.)\n","doc.vector"],"metadata":{"id":"Wxk4NV5AdL04","colab":{"base_uri":"https://localhost:8080/","height":396},"executionInfo":{"status":"error","timestamp":1651583768492,"user_tz":-120,"elapsed":1430,"user":{"displayName":"Roger Pujol","userId":"07983155497047424279"}},"outputId":"c7dc9867-3976-41bb-834b-513e149e6f7c"},"execution_count":null,"outputs":[{"output_type":"error","ename":"OSError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)","\u001b[0;32m<ipython-input-2-3bc63ed9f9b4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mspacy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# Load the spacy model that you have installed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mnlp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspacy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'en_core_web_md'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# process a sentence using the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/spacy/__init__.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(name, **overrides)\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdepr_path\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0mdeprecation_warning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mWarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW001\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdepr_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moverrides\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/spacy/util.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(name, **overrides)\u001b[0m\n\u001b[1;32m    167\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"exists\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Path or Path-like to model data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mload_model_from_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moverrides\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 169\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mErrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mE050\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mOSError\u001b[0m: [E050] Can't find model 'en_core_web_md'. It doesn't seem to be a shortcut link, a Python package or a valid path to a data directory."]}]},{"cell_type":"code","source":["#Opposites are not necessarily different\n","doc = nlp(\"I loved Narnia but hated Armageddon\")\n","\n","print(doc[1])\n","print(doc[4])\n","print(doc[1].similarity(doc[4]))\n","print(doc[4].similarity(doc[1]))\n","\n","doc = nlp(\"The king and the queen are enjoying a sumptious breakfast today\")\n","\n","print(doc[1])\n","print(doc[4])\n","print(doc[1].similarity(doc[4]))\n","print(doc[4].similarity(doc[1]))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nxqeG5FZfFna","outputId":"25fcd049-48fe-45f6-93d6-40ec2c2ac1c3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["loved\n","hated\n","0.66889775\n","0.66889775\n","king\n","queen\n","0.72526103\n","0.72526103\n"]}]},{"cell_type":"markdown","source":["WhatLies module"],"metadata":{"id":"HneOrIcxh9z1"}},{"cell_type":"code","source":["king = nlp.vocab[\"king\"].vector\n","man = nlp.vocab[\"man\"].vector\n","queen = nlp.vocab[\"queen\"].vector\n","woman = nlp.vocab[\"woman\"].vector\n","\n","#or:\n","def w2v(w=\"king\"):\n","  return nlp.vocab[w].vector\n","\n","king = w2v(\"king\")"],"metadata":{"id":"QUURX-boh9A-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from whatlies import EmbeddingSet\n","from whatlies.language import SpacyLanguage\n","\n","lang = SpacyLanguage('en_core_web_md')\n","words = ['cat', 'dog', 'fish', 'kitten', 'man', 'woman', 'king', 'queen', 'doctor', 'nurse']\n","\n","emb = lang[words]\n","emb.plot_interactive(x_axis='man', y_axis='woman')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":385},"id":"KsUIQbjskc_R","outputId":"173048ef-2a0d-4611-e2b5-93064c659ece"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["\n","<div id=\"altair-viz-a34ef04abf1345bf986ee981c845bb24\"></div>\n","<script type=\"text/javascript\">\n","  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n","  (function(spec, embedOpt){\n","    let outputDiv = document.currentScript.previousElementSibling;\n","    if (outputDiv.id !== \"altair-viz-a34ef04abf1345bf986ee981c845bb24\") {\n","      outputDiv = document.getElementById(\"altair-viz-a34ef04abf1345bf986ee981c845bb24\");\n","    }\n","    const paths = {\n","      \"vega\": \"https://cdn.jsdelivr.net/npm//vega@5?noext\",\n","      \"vega-lib\": \"https://cdn.jsdelivr.net/npm//vega-lib?noext\",\n","      \"vega-lite\": \"https://cdn.jsdelivr.net/npm//vega-lite@4.17.0?noext\",\n","      \"vega-embed\": \"https://cdn.jsdelivr.net/npm//vega-embed@6?noext\",\n","    };\n","\n","    function maybeLoadScript(lib, version) {\n","      var key = `${lib.replace(\"-\", \"\")}_version`;\n","      return (VEGA_DEBUG[key] == version) ?\n","        Promise.resolve(paths[lib]) :\n","        new Promise(function(resolve, reject) {\n","          var s = document.createElement('script');\n","          document.getElementsByTagName(\"head\")[0].appendChild(s);\n","          s.async = true;\n","          s.onload = () => {\n","            VEGA_DEBUG[key] = version;\n","            return resolve(paths[lib]);\n","          };\n","          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n","          s.src = paths[lib];\n","        });\n","    }\n","\n","    function showError(err) {\n","      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n","      throw err;\n","    }\n","\n","    function displayChart(vegaEmbed) {\n","      vegaEmbed(outputDiv, spec, embedOpt)\n","        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n","    }\n","\n","    if(typeof define === \"function\" && define.amd) {\n","      requirejs.config({paths});\n","      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n","    } else {\n","      maybeLoadScript(\"vega\", \"5\")\n","        .then(() => maybeLoadScript(\"vega-lite\", \"4.17.0\"))\n","        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n","        .catch(showError)\n","        .then(() => displayChart(vegaEmbed));\n","    }\n","  })({\"config\": {\"view\": {\"continuousWidth\": 400, \"continuousHeight\": 300}}, \"layer\": [{\"mark\": {\"type\": \"circle\", \"size\": 60}, \"encoding\": {\"color\": {\"field\": \"\", \"legend\": null, \"type\": \"nominal\"}, \"tooltip\": [{\"field\": \"name\", \"type\": \"nominal\"}, {\"field\": \"original\", \"type\": \"nominal\"}], \"x\": {\"axis\": {\"title\": \"man\"}, \"field\": \"x_axis\", \"type\": \"quantitative\"}, \"y\": {\"axis\": {\"title\": \"woman\"}, \"field\": \"y_axis\", \"type\": \"quantitative\"}}, \"selection\": {\"selector001\": {\"type\": \"interval\", \"bind\": \"scales\", \"encodings\": [\"x\", \"y\"]}}, \"title\": \"man vs. woman\"}, {\"mark\": {\"type\": \"text\", \"color\": \"black\", \"dx\": -15, \"dy\": 3}, \"encoding\": {\"text\": {\"field\": \"original\", \"type\": \"nominal\"}, \"x\": {\"field\": \"x_axis\", \"type\": \"quantitative\"}, \"y\": {\"field\": \"y_axis\", \"type\": \"quantitative\"}}}], \"data\": {\"name\": \"data-9772bd3fc4e5e10fbf898ed48ed7f201\"}, \"$schema\": \"https://vega.github.io/schema/vega-lite/v4.17.0.json\", \"datasets\": {\"data-9772bd3fc4e5e10fbf898ed48ed7f201\": [{\"x_axis\": 0.3758322596549988, \"y_axis\": 0.34616324305534363, \"name\": \"cat\", \"original\": \"cat\"}, {\"x_axis\": 0.4621913731098175, \"y_axis\": 0.4013059139251709, \"name\": \"dog\", \"original\": \"dog\"}, {\"x_axis\": 0.350157767534256, \"y_axis\": 0.2681156396865845, \"name\": \"fish\", \"original\": \"fish\"}, {\"x_axis\": 0.2800500690937042, \"y_axis\": 0.3301210403442383, \"name\": \"kitten\", \"original\": \"kitten\"}, {\"x_axis\": 1.0, \"y_axis\": 0.6816136837005615, \"name\": \"man\", \"original\": \"man\"}, {\"x_axis\": 0.8037664890289307, \"y_axis\": 1.0, \"name\": \"woman\", \"original\": \"woman\"}, {\"x_axis\": 0.45961007475852966, \"y_axis\": 0.27491992712020874, \"name\": \"king\", \"original\": \"king\"}, {\"x_axis\": 0.2914373576641083, \"y_axis\": 0.40253907442092896, \"name\": \"queen\", \"original\": \"queen\"}, {\"x_axis\": 0.4489893317222595, \"y_axis\": 0.4943573474884033, \"name\": \"doctor\", \"original\": \"doctor\"}, {\"x_axis\": 0.3271060585975647, \"y_axis\": 0.5211429595947266, \"name\": \"nurse\", \"original\": \"nurse\"}]}}, {\"mode\": \"vega-lite\"});\n","</script>"],"text/plain":["alt.LayerChart(...)"]},"metadata":{},"execution_count":45}]},{"cell_type":"code","source":[""],"metadata":{"id":"he4x501G0cdx"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Vector Algebra**\n","\n","seems much more difficult than in gensim"],"metadata":{"id":"JQhFmpmee0tE"}},{"cell_type":"code","source":["from sklearn.metrics.pairwise import cosine_similarity\n","\n","queries = [w for w in nlp.vocab if w.is_lower and w.prob >= -15]\n","\n","def cos_sim(a, b):\n","    return cosine_similarity(a.reshape(1, -1), b.reshape(1, -1))\n","\n","def most_similar_vec(vec, count=10):\n","    by_similarity = sorted(queries, key=lambda w: cos_sim(w.vector, vec), reverse=True)\n","    return [w.orth_ for w in by_similarity[:count]]\n","\n","vec = nlp('woman').vector + nlp('king').vector - nlp(\"man\").vector\n","most_similar_vec(vec)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"y8Z_BTHmj4G2","outputId":"0b6976f4-4038-4972-f297-e151a19fcda1"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['king',\n"," 'queen',\n"," 'prince',\n"," 'princes',\n"," 'kings',\n"," 'princess',\n"," 'princesses',\n"," 'mermaid',\n"," 'royal',\n"," 'royals']"]},"metadata":{},"execution_count":15}]},{"cell_type":"code","source":["queries"],"metadata":{"id":"S6eNPWlZkDXs"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## word2vec in gensim"],"metadata":{"id":"r8MsXo0HgE3a"}},{"cell_type":"code","source":["import gensim.downloader as api\n","#https://github.com/RaRe-Technologies/gensim-data\n","wv = api.load('glove-wiki-gigaword-100')#128MB\n","#wv = api.load('glove-wiki-gigaword-50')#65MB\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"69CQJjxfgUvR","outputId":"afd4f1e6-2e42-4f6d-a68a-7b5b2d5741d7","executionInfo":{"status":"ok","timestamp":1651584372387,"user_tz":-120,"elapsed":77503,"user":{"displayName":"Roger Pujol","userId":"07983155497047424279"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[==================================================] 100.0% 128.1/128.1MB downloaded\n"]}]},{"cell_type":"code","source":[""],"metadata":{"id":"gynWpK0w0eIF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["pairs = [\n","    ('car', 'minivan'),   # a minivan is a kind of car\n","    ('car', 'bicycle'),   # still a wheeled vehicle\n","    ('car', 'airplane'),  # ok, no wheels, but still a vehicle\n","    ('car', 'cereal'),    # ... and so on\n","    ('car', 'communism'),\n","]\n","for w1, w2 in pairs:\n","    print('%r\\t%r\\t%.2f' % (w1, w2, wv.similarity(w1, w2)))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EbLSL0D2g4Je","outputId":"c52c88cd-f71b-43d8-e68a-e2f0c66bad71"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["'car'\t'minivan'\t0.67\n","'car'\t'bicycle'\t0.69\n","'car'\t'airplane'\t0.65\n","'car'\t'cereal'\t0.12\n","'car'\t'communism'\t0.04\n"]}]},{"cell_type":"markdown","source":["## Data"],"metadata":{"id":"YhEZsOc7BVqY"}},{"cell_type":"markdown","source":["**IMD Movie Reviews**"],"metadata":{"id":"e3ofzmU3fbUH"}},{"cell_type":"code","source":["from tensorflow.keras.datasets import imdb\n","(train_data, train_labels), (test_data, test_labels) = imdb.load_data(\n","    num_words=10000)"],"metadata":{"id":"inHlYXX-gCJx","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1651667275746,"user_tz":-120,"elapsed":5292,"user":{"displayName":"Roger Pujol","userId":"07983155497047424279"}},"outputId":"8efde45d-6468-465b-9ce9-ee573f0719b1"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n","17465344/17464789 [==============================] - 0s 0us/step\n","17473536/17464789 [==============================] - 0s 0us/step\n"]}]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')\n","DATA_PATH = \"/content/drive/Othercomputers/Mi portátil/Master/GitHub/twsm-PERSONAL\"\n","\n","#from TWSM import *\n","from tensorflow import keras\n","from tensorflow.keras import layers\n","import spacy\n","## Import packages\n","import pickle\n","import pandas as pd\n","from gensim.models import Word2Vec\n","import spacy\n","\n","# run this from a normal command line\n","#!python -m spacy download en_core_web_md #160MB"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nzlk0sSsBhpt","executionInfo":{"status":"ok","timestamp":1651667022642,"user_tz":-120,"elapsed":24867,"user":{"displayName":"Roger Pujol","userId":"07983155497047424279"}},"outputId":"8cb31046-1a56-419d-cd55-2c4888fe2e8d"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"markdown","source":["#### Tasks\n","\n","1. Train a word2vec model of dimension $100$ on the IMD data. (considering words appearing in more than 50 documents) Save the model if you like.\n","\n","2. Compute the embedding for each review (average word2vec)\n","\n","3. Fit a keras classifier to the embedded reviews. (2 hidden layers of size 40 each) Report/Monitor the accuracy on the test data.\n","\n","4. Load the bing sentiment dictionary. Compute two separate embeddings for the negative and positive sentiments.\n","\n","5. Compute the similarity between these two vectors and a few selected reviews. Does it agree with their label?\n"],"metadata":{"id":"eA-8MKLQjT1U"}},{"cell_type":"markdown","source":["# **Examine Data**"],"metadata":{"id":"6msqADS2D_Lc"}},{"cell_type":"code","source":["print(train_data.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hs4z4TJhD-ik","executionInfo":{"status":"ok","timestamp":1651668503996,"user_tz":-120,"elapsed":225,"user":{"displayName":"Roger Pujol","userId":"07983155497047424279"}},"outputId":"5a0d5764-08d8-4be2-dab6-76761a85d2fc"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["(25000,)\n"]}]},{"cell_type":"code","source":["print(train_labels.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3h33MaV2E2RV","executionInfo":{"status":"ok","timestamp":1651668511716,"user_tz":-120,"elapsed":222,"user":{"displayName":"Roger Pujol","userId":"07983155497047424279"}},"outputId":"b92a0893-8e25-4f0c-bbc0-d42e606296ef"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["(25000,)\n"]}]},{"cell_type":"markdown","source":["# **Reviews back to text**"],"metadata":{"id":"tzRP_g72IRY8"}},{"cell_type":"code","source":["word_index = imdb.get_word_index()\n","reverse_word_index = dict(\n","    [(value, key) for (key, value) in word_index.items()])\n","decoded_reviews = \" \".join(\n","    [reverse_word_index.get(i - 3, \"?\") for i in train_data[0]])\n","\n","decoded_reviews"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":122},"id":"mTN3XowWIUPC","executionInfo":{"status":"ok","timestamp":1651669459982,"user_tz":-120,"elapsed":277,"user":{"displayName":"Roger Pujol","userId":"07983155497047424279"}},"outputId":"7e8addf6-af56-4af1-95bc-f66e69a33fa8"},"execution_count":22,"outputs":[{"output_type":"execute_result","data":{"text/plain":["\"? this film was just brilliant casting location scenery story direction everyone's really suited the part they played and you could just imagine being there robert ? is an amazing actor and now the same being director ? father came from the same scottish island as myself so i loved the fact there was a real connection with this film the witty remarks throughout the film were great it was just brilliant so much that i bought the film as soon as it was released for ? and would recommend it to everyone to watch and the fly fishing was amazing really cried at the end it was so sad and you know what they say if you cry at a film it must have been good and this definitely was also ? to the two little boy's that played the ? of norman and paul they were just brilliant children are often left out of the ? list i think because the stars that play them all grown up are such a big profile for the whole film but these children are amazing and should be praised for what they have done don't you think the whole story was so lovely because it was true and was someone's life after all that was shared with us all\""],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":22}]},{"cell_type":"code","source":["N=len(train_data)\n","decoded_reviews = [\"\" for x in range(N)]\n","\n","for j in range(N):\n","  decoded_reviews[j] = \" \".join(\n","    [reverse_word_index.get(i - 3, \"?\") for i in train_data[j]])"],"metadata":{"id":"DrzaAAMzIlzg","executionInfo":{"status":"ok","timestamp":1651669464751,"user_tz":-120,"elapsed":1911,"user":{"displayName":"Roger Pujol","userId":"07983155497047424279"}}},"execution_count":23,"outputs":[]},{"cell_type":"code","source":["decoded_reviews[1]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":105},"id":"roQ4ZF8LMp6_","executionInfo":{"status":"ok","timestamp":1651670231345,"user_tz":-120,"elapsed":226,"user":{"displayName":"Roger Pujol","userId":"07983155497047424279"}},"outputId":"fa862aa3-3f40-45b5-df6a-98081c7b1102"},"execution_count":30,"outputs":[{"output_type":"execute_result","data":{"text/plain":["\"? big hair big boobs bad music and a giant safety pin these are the words to best describe this terrible movie i love cheesy horror movies and i've seen hundreds but this had got to be on of the worst ever made the plot is paper thin and ridiculous the acting is an abomination the script is completely laughable the best is the end showdown with the cop and how he worked out who the killer is it's just so damn terribly written the clothes are sickening and funny in equal ? the hair is big lots of boobs ? men wear those cut ? shirts that show off their ? sickening that men actually wore them and the music is just ? trash that plays over and over again in almost every scene there is trashy music boobs and ? taking away bodies and the gym still doesn't close for ? all joking aside this is a truly bad film whose only charm is to look back on the disaster that was the 80's and have a good old laugh at how bad everything was back then\""],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":30}]},{"cell_type":"markdown","source":["# **Model**"],"metadata":{"id":"AU-l41WXI6qo"}},{"cell_type":"code","source":["corpus=[doc.split() for doc in decoded_reviews]"],"metadata":{"id":"k5qy_X-BK667","executionInfo":{"status":"ok","timestamp":1651669470497,"user_tz":-120,"elapsed":967,"user":{"displayName":"Roger Pujol","userId":"07983155497047424279"}}},"execution_count":24,"outputs":[]},{"cell_type":"code","source":["model = Word2Vec(corpus, size=100, min_count=50)"],"metadata":{"id":"as_iRvH-GfSN","executionInfo":{"status":"ok","timestamp":1651669919238,"user_tz":-120,"elapsed":42414,"user":{"displayName":"Roger Pujol","userId":"07983155497047424279"}}},"execution_count":25,"outputs":[]},{"cell_type":"code","source":["model.save(\"word2vec.model\")\n","print(model)"],"metadata":{"id":"d053MV6TGg75","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1651670259157,"user_tz":-120,"elapsed":229,"user":{"displayName":"Roger Pujol","userId":"07983155497047424279"}},"outputId":"cc8a499b-eb73-4547-87c2-44d6c543fcc3"},"execution_count":31,"outputs":[{"output_type":"stream","name":"stdout","text":["Word2Vec(vocab=7261, size=100, alpha=0.025)\n"]}]},{"cell_type":"markdown","source":["# **Average Word2vec**"],"metadata":{"id":"ebtPBDSaPrtd"}},{"cell_type":"code","source":["# Document representation for the text\n","corpus_w2v=[[model.wv[word] for word in doc if word in model.wv.vocab.keys()] for doc in corpus]\n","positive=[i for i in range(len(corpus)) if len(corpus_w2v[i])>0]\n","\n","corpus_w2v2=[corpus_w2v[i] for i in positive]\n","\n","# Document average representation\n","corpus_w2v_avg_clean=[sum(words)/len(words) for words in corpus_w2v2]\n","\n","# This corpus can be used later in clustering and classification tasks\n","print(corpus_w2v_avg_clean[10])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cjIqDmOmPqff","executionInfo":{"status":"ok","timestamp":1651670939826,"user_tz":-120,"elapsed":16126,"user":{"displayName":"Roger Pujol","userId":"07983155497047424279"}},"outputId":"86492f63-8195-4d60-fcec-ba92617c0b4f"},"execution_count":35,"outputs":[{"output_type":"stream","name":"stdout","text":["[-0.13179548 -0.13428992 -0.18508519  0.05798002  0.11014589 -0.08045991\n"," -0.28172222  0.09762453  0.2570829  -0.03372364  0.2264569   0.17756997\n","  0.39125568 -0.16930884 -0.2592233   0.5050119   0.25508517 -0.22835918\n","  0.03023599 -0.27985355  0.00683441  0.03405618  0.12408944 -0.28738195\n"," -0.18141137 -0.12173939 -0.099632    0.02689914 -0.06626983 -0.2208648\n"," -0.3282246   0.22681588 -0.18801802 -0.2329783  -0.20070703  0.52878934\n"," -0.16635163  0.20430443 -0.1351676   0.6688067  -0.5507718   0.41877732\n","  0.04052142  0.17801255  0.2701071  -0.33845407  0.05278147 -0.0515018\n"," -0.33697695  0.56693256 -0.21323766  0.03803716  0.15625826  0.03573452\n"," -0.44171822  0.01271552  0.23872529  0.11314425 -0.07062407 -0.08412804\n"," -0.00600381  0.37189963 -0.11365755  0.3199189   0.04081683 -0.08059935\n"," -0.13741228 -0.10910499  0.05957192  0.15013348 -0.27011198 -0.04556013\n","  0.08208993  0.03683763  0.05591073 -0.01929143 -0.3782493   0.42942774\n"," -0.14842434  0.2834748  -0.12511815 -0.32975313 -0.19579375  0.02742104\n","  0.18466303 -0.06348573  0.31001365 -0.22622998  0.10643142 -0.08463755\n","  0.0681694  -0.12273155 -0.21116132  0.08146808  0.4542115   0.09011509\n"," -0.09809599  0.06513543  0.93686134  0.03045593]\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OKUP2dEI-y51","outputId":"d3446a8f-cf9c-4c6d-8308-7553d0c5fe92","executionInfo":{"status":"ok","timestamp":1651670985118,"user_tz":-120,"elapsed":246,"user":{"displayName":"Roger Pujol","userId":"07983155497047424279"}}},"source":["len(corpus_w2v)"],"execution_count":36,"outputs":[{"output_type":"execute_result","data":{"text/plain":["25000"]},"metadata":{},"execution_count":36}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3p2H3WBAAdLk","outputId":"74012198-0e91-40d1-ecd2-39a1b3c0ffce","executionInfo":{"status":"ok","timestamp":1651670985815,"user_tz":-120,"elapsed":3,"user":{"displayName":"Roger Pujol","userId":"07983155497047424279"}}},"source":["len(corpus_w2v_avg_clean)"],"execution_count":37,"outputs":[{"output_type":"execute_result","data":{"text/plain":["25000"]},"metadata":{},"execution_count":37}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xp3DPPMfvduE","outputId":"e7b674a3-6f86-4a91-9e1e-98e9c23f083c","executionInfo":{"status":"ok","timestamp":1651670991906,"user_tz":-120,"elapsed":2,"user":{"displayName":"Roger Pujol","userId":"07983155497047424279"}}},"source":["model.wv.similar_by_vector(corpus_w2v_avg_clean[0])"],"execution_count":39,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[('it', 0.7002661824226379),\n"," ('really', 0.6868996024131775),\n"," ('just', 0.6563368439674377),\n"," ('actually', 0.6291176080703735),\n"," ('this', 0.6163733005523682),\n"," ('bad', 0.600469708442688),\n"," ('disappointed', 0.598484456539154),\n"," ('movie', 0.592471182346344),\n"," ('good', 0.5775361061096191),\n"," ('funny', 0.5705164670944214)]"]},"metadata":{},"execution_count":39}]},{"cell_type":"code","metadata":{"id":"Rk3iCFMnVPco","colab":{"base_uri":"https://localhost:8080/","height":300},"outputId":"36f1c084-10a9-4c9e-ccdb-f27d5ab17c31","executionInfo":{"status":"ok","timestamp":1651671060888,"user_tz":-120,"elapsed":1510,"user":{"displayName":"Roger Pujol","userId":"07983155497047424279"}}},"source":["# Corpus as data frame that can be used in downstream tasks such as classification\n","corpus_w2v_avg_df=pd.DataFrame(corpus_w2v_avg_clean)\n","ecorpus_w2v_avg_df.head()"],"execution_count":43,"outputs":[{"output_type":"execute_result","data":{"text/plain":["         0         1         2         3         4         5         6   \\\n","0  0.002547 -0.053586  0.110606  0.271018  0.018488 -0.312736 -0.358602   \n","1 -0.002277 -0.166709 -0.021454  0.282407  0.232869 -0.284560 -0.392670   \n","2  0.086036  0.164436  0.080638  0.153089 -0.100223  0.060261 -0.331279   \n","3 -0.204331  0.111560 -0.181981 -0.206662  0.001540 -0.224015  0.014030   \n","4 -0.160111  0.214807 -0.030208  0.059089 -0.440250 -0.041743 -0.216256   \n","\n","         7         8         9   ...        90        91        92        93  \\\n","0  0.001325  0.559362 -0.102771  ...  0.215092 -0.482986 -0.038197  0.389945   \n","1  0.136791  0.196933  0.140207  ...  0.220437 -0.061238 -0.302896  0.257258   \n","2  0.094121  0.291988  0.150128  ...  0.049495 -0.375090 -0.050422  0.489581   \n","3  0.157554  0.185863 -0.049888  ...  0.193298 -0.182343 -0.167690  0.136011   \n","4 -0.013227  0.324131  0.271408  ...  0.166917 -0.423361  0.022852  0.541207   \n","\n","         94        95        96        97        98        99  \n","0  0.509781  0.136070  0.007076 -0.032305  1.053163 -0.154776  \n","1  0.278716  0.124231 -0.345381  0.105101  0.775254 -0.016696  \n","2  0.719987  0.246373 -0.062145 -0.046875  1.023154 -0.105591  \n","3  0.197434  0.073042 -0.128013 -0.019613  0.726028  0.011240  \n","4  0.496034  0.330351 -0.211074  0.046276  1.250896 -0.075437  \n","\n","[5 rows x 100 columns]"],"text/html":["\n","  <div id=\"df-51305273-2a8c-4f64-b01c-d7449dffb85c\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>0</th>\n","      <th>1</th>\n","      <th>2</th>\n","      <th>3</th>\n","      <th>4</th>\n","      <th>5</th>\n","      <th>6</th>\n","      <th>7</th>\n","      <th>8</th>\n","      <th>9</th>\n","      <th>...</th>\n","      <th>90</th>\n","      <th>91</th>\n","      <th>92</th>\n","      <th>93</th>\n","      <th>94</th>\n","      <th>95</th>\n","      <th>96</th>\n","      <th>97</th>\n","      <th>98</th>\n","      <th>99</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.002547</td>\n","      <td>-0.053586</td>\n","      <td>0.110606</td>\n","      <td>0.271018</td>\n","      <td>0.018488</td>\n","      <td>-0.312736</td>\n","      <td>-0.358602</td>\n","      <td>0.001325</td>\n","      <td>0.559362</td>\n","      <td>-0.102771</td>\n","      <td>...</td>\n","      <td>0.215092</td>\n","      <td>-0.482986</td>\n","      <td>-0.038197</td>\n","      <td>0.389945</td>\n","      <td>0.509781</td>\n","      <td>0.136070</td>\n","      <td>0.007076</td>\n","      <td>-0.032305</td>\n","      <td>1.053163</td>\n","      <td>-0.154776</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>-0.002277</td>\n","      <td>-0.166709</td>\n","      <td>-0.021454</td>\n","      <td>0.282407</td>\n","      <td>0.232869</td>\n","      <td>-0.284560</td>\n","      <td>-0.392670</td>\n","      <td>0.136791</td>\n","      <td>0.196933</td>\n","      <td>0.140207</td>\n","      <td>...</td>\n","      <td>0.220437</td>\n","      <td>-0.061238</td>\n","      <td>-0.302896</td>\n","      <td>0.257258</td>\n","      <td>0.278716</td>\n","      <td>0.124231</td>\n","      <td>-0.345381</td>\n","      <td>0.105101</td>\n","      <td>0.775254</td>\n","      <td>-0.016696</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0.086036</td>\n","      <td>0.164436</td>\n","      <td>0.080638</td>\n","      <td>0.153089</td>\n","      <td>-0.100223</td>\n","      <td>0.060261</td>\n","      <td>-0.331279</td>\n","      <td>0.094121</td>\n","      <td>0.291988</td>\n","      <td>0.150128</td>\n","      <td>...</td>\n","      <td>0.049495</td>\n","      <td>-0.375090</td>\n","      <td>-0.050422</td>\n","      <td>0.489581</td>\n","      <td>0.719987</td>\n","      <td>0.246373</td>\n","      <td>-0.062145</td>\n","      <td>-0.046875</td>\n","      <td>1.023154</td>\n","      <td>-0.105591</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>-0.204331</td>\n","      <td>0.111560</td>\n","      <td>-0.181981</td>\n","      <td>-0.206662</td>\n","      <td>0.001540</td>\n","      <td>-0.224015</td>\n","      <td>0.014030</td>\n","      <td>0.157554</td>\n","      <td>0.185863</td>\n","      <td>-0.049888</td>\n","      <td>...</td>\n","      <td>0.193298</td>\n","      <td>-0.182343</td>\n","      <td>-0.167690</td>\n","      <td>0.136011</td>\n","      <td>0.197434</td>\n","      <td>0.073042</td>\n","      <td>-0.128013</td>\n","      <td>-0.019613</td>\n","      <td>0.726028</td>\n","      <td>0.011240</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>-0.160111</td>\n","      <td>0.214807</td>\n","      <td>-0.030208</td>\n","      <td>0.059089</td>\n","      <td>-0.440250</td>\n","      <td>-0.041743</td>\n","      <td>-0.216256</td>\n","      <td>-0.013227</td>\n","      <td>0.324131</td>\n","      <td>0.271408</td>\n","      <td>...</td>\n","      <td>0.166917</td>\n","      <td>-0.423361</td>\n","      <td>0.022852</td>\n","      <td>0.541207</td>\n","      <td>0.496034</td>\n","      <td>0.330351</td>\n","      <td>-0.211074</td>\n","      <td>0.046276</td>\n","      <td>1.250896</td>\n","      <td>-0.075437</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows × 100 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-51305273-2a8c-4f64-b01c-d7449dffb85c')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-51305273-2a8c-4f64-b01c-d7449dffb85c button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-51305273-2a8c-4f64-b01c-d7449dffb85c');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":43}]},{"cell_type":"markdown","source":["# **Keras Classifier**"],"metadata":{"id":"U9b3BG-3TvbV"}},{"cell_type":"code","source":["clf = keras.Sequential()\n","clf.add(layers.Dense(40))\n","clf.add(layers.Dense(40))"],"metadata":{"id":"CFcaB0UhTxyF","executionInfo":{"status":"ok","timestamp":1651671924245,"user_tz":-120,"elapsed":245,"user":{"displayName":"Roger Pujol","userId":"07983155497047424279"}}},"execution_count":44,"outputs":[]},{"cell_type":"code","source":["clf.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=['accuracy'])"],"metadata":{"id":"KPnb-bYvUjDa","executionInfo":{"status":"ok","timestamp":1651672492203,"user_tz":-120,"elapsed":241,"user":{"displayName":"Roger Pujol","userId":"07983155497047424279"}}},"execution_count":57,"outputs":[]},{"cell_type":"code","source":["clf.fit(np.array(corpus_w2v_avg_clean),\n","                    train_labels,\n","                    epochs=20,\n","                    validation_split=0.3)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_x2jsJRlUGjf","executionInfo":{"status":"ok","timestamp":1651672535645,"user_tz":-120,"elapsed":41840,"user":{"displayName":"Roger Pujol","userId":"07983155497047424279"}},"outputId":"0120ae48-5771-4928-cc19-4a6afce51ca8"},"execution_count":58,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/20\n","547/547 [==============================] - 2s 3ms/step - loss: 0.9951 - accuracy: 0.0014 - val_loss: 0.5076 - val_accuracy: 0.0000e+00\n","Epoch 2/20\n","547/547 [==============================] - 1s 2ms/step - loss: 0.4790 - accuracy: 0.0000e+00 - val_loss: 0.4707 - val_accuracy: 0.0000e+00\n","Epoch 3/20\n","547/547 [==============================] - 1s 2ms/step - loss: 0.4596 - accuracy: 0.0013 - val_loss: 0.4508 - val_accuracy: 0.0052\n","Epoch 4/20\n","547/547 [==============================] - 1s 2ms/step - loss: 0.5043 - accuracy: 0.0013 - val_loss: 0.4453 - val_accuracy: 4.0000e-04\n","Epoch 5/20\n","547/547 [==============================] - 1s 2ms/step - loss: 0.9169 - accuracy: 0.0187 - val_loss: 7.7238 - val_accuracy: 0.0000e+00\n","Epoch 6/20\n","547/547 [==============================] - 1s 2ms/step - loss: 7.5766 - accuracy: 0.0000e+00 - val_loss: 7.7223 - val_accuracy: 0.0000e+00\n","Epoch 7/20\n","547/547 [==============================] - 1s 2ms/step - loss: 7.5718 - accuracy: 0.0000e+00 - val_loss: 7.7102 - val_accuracy: 0.0000e+00\n","Epoch 8/20\n","547/547 [==============================] - 1s 2ms/step - loss: 6.5933 - accuracy: 4.5714e-04 - val_loss: 0.6841 - val_accuracy: 0.0073\n","Epoch 9/20\n","547/547 [==============================] - 1s 2ms/step - loss: 2.1855 - accuracy: 0.0027 - val_loss: 0.8072 - val_accuracy: 1.3333e-04\n","Epoch 10/20\n","547/547 [==============================] - 1s 2ms/step - loss: 0.6852 - accuracy: 7.4286e-04 - val_loss: 0.6489 - val_accuracy: 0.0000e+00\n","Epoch 11/20\n","547/547 [==============================] - 2s 3ms/step - loss: 0.6911 - accuracy: 9.7143e-04 - val_loss: 0.7097 - val_accuracy: 0.0000e+00\n","Epoch 12/20\n","547/547 [==============================] - 1s 2ms/step - loss: 0.6608 - accuracy: 0.0012 - val_loss: 0.6261 - val_accuracy: 0.0017\n","Epoch 13/20\n","547/547 [==============================] - 1s 2ms/step - loss: 0.8345 - accuracy: 5.7143e-04 - val_loss: 0.7565 - val_accuracy: 0.0000e+00\n","Epoch 14/20\n","547/547 [==============================] - 1s 2ms/step - loss: 0.6812 - accuracy: 0.0014 - val_loss: 0.6243 - val_accuracy: 0.0195\n","Epoch 15/20\n","547/547 [==============================] - 1s 2ms/step - loss: 0.5520 - accuracy: 0.0057 - val_loss: 0.4804 - val_accuracy: 0.0108\n","Epoch 16/20\n","547/547 [==============================] - 2s 3ms/step - loss: 0.4775 - accuracy: 0.0117 - val_loss: 0.4621 - val_accuracy: 0.0207\n","Epoch 17/20\n","547/547 [==============================] - 1s 2ms/step - loss: 0.4704 - accuracy: 0.0199 - val_loss: 0.4619 - val_accuracy: 0.0271\n","Epoch 18/20\n","547/547 [==============================] - 1s 2ms/step - loss: 1.8467 - accuracy: 0.0211 - val_loss: 0.6897 - val_accuracy: 0.0168\n","Epoch 19/20\n","547/547 [==============================] - 1s 2ms/step - loss: 1.8255 - accuracy: 0.0221 - val_loss: 1.2593 - val_accuracy: 0.0687\n","Epoch 20/20\n","547/547 [==============================] - 1s 2ms/step - loss: 0.9128 - accuracy: 0.0215 - val_loss: 0.7885 - val_accuracy: 0.0031\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7fc7bfffb9d0>"]},"metadata":{},"execution_count":58}]},{"cell_type":"code","source":["clf.evaluate"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6e4Cu9RrVCLY","executionInfo":{"status":"ok","timestamp":1651672406085,"user_tz":-120,"elapsed":216,"user":{"displayName":"Roger Pujol","userId":"07983155497047424279"}},"outputId":"d97d8586-118a-465a-961d-103dafd781ea"},"execution_count":54,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<bound method Model.evaluate of <keras.engine.sequential.Sequential object at 0x7fc7d18e5f90>>"]},"metadata":{},"execution_count":54}]},{"cell_type":"code","source":["# train test???"],"metadata":{"id":"HDL-RocCWtBI"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **Bing**"],"metadata":{"id":"SDL-rCUNWvM8"}},{"cell_type":"code","source":["bing_df = pd.read_csv(\"/content/drive/Othercomputers/Mi portátil/Master/GitHub/DataScience2021/TWSM/bing.csv\", index_col=0)\n","bing_df.head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"KTZxr4y4Wxmc","executionInfo":{"status":"ok","timestamp":1651672855152,"user_tz":-120,"elapsed":280,"user":{"displayName":"Roger Pujol","userId":"07983155497047424279"}},"outputId":"cac953c1-d814-4370-89fe-d6d37ac6dee1"},"execution_count":62,"outputs":[{"output_type":"execute_result","data":{"text/plain":["         word sentiment\n","1     2-faces  negative\n","2    abnormal  negative\n","3     abolish  negative\n","4  abominable  negative\n","5  abominably  negative"],"text/html":["\n","  <div id=\"df-d8dcd096-5008-42b0-9c44-2a0452ebe6f5\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>word</th>\n","      <th>sentiment</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>1</th>\n","      <td>2-faces</td>\n","      <td>negative</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>abnormal</td>\n","      <td>negative</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>abolish</td>\n","      <td>negative</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>abominable</td>\n","      <td>negative</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>abominably</td>\n","      <td>negative</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d8dcd096-5008-42b0-9c44-2a0452ebe6f5')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-d8dcd096-5008-42b0-9c44-2a0452ebe6f5 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-d8dcd096-5008-42b0-9c44-2a0452ebe6f5');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":62}]},{"cell_type":"code","source":["bing_pos = bing_df[bing_df[\"sentiment\"] == \"positive\"]\n","bing_pos = bing_pos[[\"word\"]]"],"metadata":{"id":"KoYksF3WX7ym","executionInfo":{"status":"ok","timestamp":1651673962013,"user_tz":-120,"elapsed":237,"user":{"displayName":"Roger Pujol","userId":"07983155497047424279"}}},"execution_count":93,"outputs":[]},{"cell_type":"code","source":["bing_neg = bing_df[bing_df[\"sentiment\"] == \"negative\"]\n","bing_neg = bing_neg[[\"word\"]]"],"metadata":{"id":"VdjXI9JqYKLx","executionInfo":{"status":"ok","timestamp":1651673965204,"user_tz":-120,"elapsed":425,"user":{"displayName":"Roger Pujol","userId":"07983155497047424279"}}},"execution_count":94,"outputs":[]},{"cell_type":"code","source":["decoded_reviews[1]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":105},"id":"d4LkvmT3cqjh","executionInfo":{"status":"ok","timestamp":1651674112241,"user_tz":-120,"elapsed":229,"user":{"displayName":"Roger Pujol","userId":"07983155497047424279"}},"outputId":"bb081194-9350-4c51-dea8-d5ab1c11c8a9"},"execution_count":97,"outputs":[{"output_type":"execute_result","data":{"text/plain":["\"? big hair big boobs bad music and a giant safety pin these are the words to best describe this terrible movie i love cheesy horror movies and i've seen hundreds but this had got to be on of the worst ever made the plot is paper thin and ridiculous the acting is an abomination the script is completely laughable the best is the end showdown with the cop and how he worked out who the killer is it's just so damn terribly written the clothes are sickening and funny in equal ? the hair is big lots of boobs ? men wear those cut ? shirts that show off their ? sickening that men actually wore them and the music is just ? trash that plays over and over again in almost every scene there is trashy music boobs and ? taking away bodies and the gym still doesn't close for ? all joking aside this is a truly bad film whose only charm is to look back on the disaster that was the 80's and have a good old laugh at how bad everything was back then\""],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":97}]},{"cell_type":"code","source":["doc = clf(decoded_reviews[1])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":626},"id":"MyZWlcDCbvBX","executionInfo":{"status":"error","timestamp":1651674156064,"user_tz":-120,"elapsed":322,"user":{"displayName":"Roger Pujol","userId":"07983155497047424279"}},"outputId":"5ba53054-b3b6-4d47-94d1-83cd312c1aa6"},"execution_count":99,"outputs":[{"output_type":"stream","name":"stdout","text":["WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor. Received: inputs=? big hair big boobs bad music and a giant safety pin these are the words to best describe this terrible movie i love cheesy horror movies and i've seen hundreds but this had got to be on of the worst ever made the plot is paper thin and ridiculous the acting is an abomination the script is completely laughable the best is the end showdown with the cop and how he worked out who the killer is it's just so damn terribly written the clothes are sickening and funny in equal ? the hair is big lots of boobs ? men wear those cut ? shirts that show off their ? sickening that men actually wore them and the music is just ? trash that plays over and over again in almost every scene there is trashy music boobs and ? taking away bodies and the gym still doesn't close for ? all joking aside this is a truly bad film whose only charm is to look back on the disaster that was the 80's and have a good old laugh at how bad everything was back then. Consider rewriting this model with the Functional API.\n"]},{"output_type":"error","ename":"TypeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-99-f60f71f4ec54>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecoded_reviews\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/input_spec.py\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[0;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[1;32m    195\u001b[0m     \u001b[0;31m# have a `shape` attribute.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'shape'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 197\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Inputs to a layer should be tensors. Got: {x}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_spec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: Exception encountered when calling layer \"sequential\" (type Sequential).\n\nInputs to a layer should be tensors. Got: ? big hair big boobs bad music and a giant safety pin these are the words to best describe this terrible movie i love cheesy horror movies and i've seen hundreds but this had got to be on of the worst ever made the plot is paper thin and ridiculous the acting is an abomination the script is completely laughable the best is the end showdown with the cop and how he worked out who the killer is it's just so damn terribly written the clothes are sickening and funny in equal ? the hair is big lots of boobs ? men wear those cut ? shirts that show off their ? sickening that men actually wore them and the music is just ? trash that plays over and over again in almost every scene there is trashy music boobs and ? taking away bodies and the gym still doesn't close for ? all joking aside this is a truly bad film whose only charm is to look back on the disaster that was the 80's and have a good old laugh at how bad everything was back then\n\nCall arguments received:\n  • inputs=\"? big hair big boobs bad music and a giant safety pin these are the words to best describe this terrible movie i love cheesy horror movies and i've seen hundreds but this had got to be on of the worst ever made the plot is paper thin and ridiculous the acting is an abomination the script is completely laughable the best is the end showdown with the cop and how he worked out who the killer is it's just so damn terribly written the clothes are sickening and funny in equal ? the hair is big lots of boobs ? men wear those cut ? shirts that show off their ? sickening that men actually wore them and the music is just ? trash that plays over and over again in almost every scene there is trashy music boobs and ? taking away bodies and the gym still doesn't close for ? all joking aside this is a truly bad film whose only charm is to look back on the disaster that was the 80's and have a good old laugh at how bad everything was back then\"\n  • training=None\n  • mask=None"]}]}],"metadata":{"colab":{"name":"Class5.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.3"}},"nbformat":4,"nbformat_minor":0}